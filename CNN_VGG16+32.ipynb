{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_VGG16+32.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8u0nkKW3dmh"
      },
      "source": [
        "# Biến thể của Convolution Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLTFRsr03rWD"
      },
      "source": [
        "**VGG16**\n",
        "\n",
        "Architect của VGG 16 bao gồm 16 layers: 2 layer conv-conv,3 layer conv-conv-conv) đều có kernel 3×3, sau mỗi layer conv là maxpooling downsize xuống 0.5, và 3 layer fully connection. VGG19 tương tự như VGG16 nhưng có thêm 3 layer convolution ở 3 layer conv cuối ( thành 4 conv stack với nhau).\n",
        "\n",
        "![image](https://dlapplications.github.io/img/20180707/cnn10.jpg)\n",
        "\n",
        "https://youtu.be/bEsRLXY7GCo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOkzXU35S-xb"
      },
      "source": [
        "**Implement VGG16 with Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3eZsRzCTF_P"
      },
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNSGPnoHW01f"
      },
      "source": [
        "trdata = ImageDataGenerator()\n",
        "traindata = trdata.flow_from_directory(directory=\"data\",target_size=(224,224))\n",
        "tsdata = ImageDataGenerator()\n",
        "testdata = tsdata.flow_from_directory(directory=\"test\", target_size=(224,224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdgCbvwyW5l7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZjVh9-gXAno"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPQrtkf3XjgA"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "hist = model.fit_generator(steps_per_epoch=100,generator=traindata, validation_data= testdata, validation_steps=10,epochs=100,callbacks=[checkpoint,early])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoq92AsIXp-C"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history[\"acc\"])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYdtnYyCXsFa"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "img = image.load_img(\"image.jpeg\",target_size=(224,224))\n",
        "img = np.asarray(img)\n",
        "plt.imshow(img)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "from keras.models import load_model\n",
        "saved_model = load_model(\"vgg16_1.h5\")\n",
        "output = saved_model.predict(img)\n",
        "if output[0][0] > output[0][1]:\n",
        "    print(\"cat\")\n",
        "else:\n",
        "    print('dog')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejJh-7ujyXwu"
      },
      "source": [
        "# Kiến trúc mạng ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKX5x2qrA6xC"
      },
      "source": [
        "**Mạng ResNet** là một mạng CNN được thiết kế để làm việc với hàng trăm hoặc hàng nghìn lớp chập. Một vấn đề xảy ra khi xây dựng mạng CNN với nhiều lớp chập sẽ xảy ra hiện tượng Vanishing Gradient dẫn tới quá trình học tập không tốt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBUlxVwyAXne"
      },
      "source": [
        "ResNet sử dụng kết nối \"tắt\" đồng nhất để xuyên qua một hay nhiều lớp. Một khối như vậy được gọi là một Residual Block, như trong hình sau :\n",
        "![image](https://images.viblo.asia/9fc720ba-45e4-4d2f-8b58-5926350bc075.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7toqNM9BJ5V"
      },
      "source": [
        "**Xây dựng mạng ResNet-50**\n",
        "\n",
        "![image](https://images.viblo.asia/fe5b21e5-3ad3-4419-93e0-7aa77a662bdd.png)\n",
        "\n",
        "*   Zero-padding : Input với (3, 3)\n",
        "*   Stage 1 : Tích chập (Conv1) với 64 filters với shape(7, 7), sử dụng stride (2, 2). BatchNorm, MaxPooling (3, 3).\n",
        "*   Stage 2 : Convolutiontal block sử dụng 3 filter với size 64x64x256, f=3, s = 1. Có 2 Identity blocks với filter size 64x64x256, f = 3.\n",
        "*   Stage 3 : Convolutional sử dụng 3 filter size 128x128x512, f=3,s=2. Có 3 Identity blocks với filter size 128x128x512, f=3.\n",
        "*   Stage 4 : Convolutional sử dụng 3 filter size 256x256x1024, f=3,s=2. Có 5 Identity blocks với filter size 256x256x1024, f=3.\n",
        "*   Stage 5 :Convolutional sử dụng 3 filter size 512x512x2048, f=3,s=2. Có 2 Identity blocks với filter size 512x512x2048, f=3.\n",
        "*   The 2D Average Pooling : sử dụng với kích thước (2, 2).\n",
        "*   The Flatten.\n",
        "*   Fully Connected (Dense) : sử dụng softmax activation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKoX4MNafwKy"
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D()(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfIecFIfzE9-"
      },
      "source": [
        "BatchNormalization có weight nhưng không học theo Gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn1wiXQWlh-C"
      },
      "source": [
        "def batchnorm_backward(dout, cache):\n",
        "    \"\"\"\n",
        "    Backward pass for batch normalization.\n",
        "    Use a computation graph for batch normalization and propagate gradients \n",
        "    backward through intermediate nodes.\n",
        "    Inputs:\n",
        "    - dout: Upstream derivatives, of shape (N, D)\n",
        "    - cache: Variable of intermediates from batchnorm_forward.\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to inputs x, of shape (N, D)\n",
        "    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)\n",
        "    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)\n",
        "    \"\"\"\n",
        "    N = dout.shape[0]\n",
        "    x_norm, x_centered, std, gamma = cache\n",
        "    dgamma = (dout * x_norm).sum(axis=0)\n",
        "    dbeta = dout.sum(axis=0)\n",
        "    \n",
        "    dx_norm = dout * gamma\n",
        "    dx_centered = dx_norm / std\n",
        "    dmean = -(dx_centered.sum(axis=0) + 2/N * x_centered.sum(axis=0))\n",
        "    dstd = (dx_norm * x_centered * -std**(-2)).sum(axis=0)\n",
        "    dvar = dstd / 2 / std\n",
        "    dx = dx_centered + (dmean + dvar * 2 * x_centered) / N\n",
        "\n",
        "    return dx, dgamma, dbeta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4JuVqlals10"
      },
      "source": [
        "def batchnorm_backward_alt(dout, cache):\n",
        "    \"\"\"\n",
        "    Alternative backward pass for batch normalization.\n",
        "    Work out the derivatives for the batch normalizaton backward pass on paper \n",
        "    and simplify as much as possible.\n",
        "    \n",
        "    Note: This implementation receives the same cache variable as \n",
        "    batchnorm_backward, but does not use all of the values in the cache.\n",
        "    Inputs / outputs: Same as batchnorm_backward\n",
        "    \"\"\"\n",
        "    N = dout.shape[0]\n",
        "    x_norm, x_centered, std, gamma = cache\n",
        "    \n",
        "    dgamma = (dout * x_norm).sum(axis=0)\n",
        "    dbeta = dout.sum(axis=0)\n",
        "    \n",
        "    dx_norm = dout * gamma\n",
        "    dx = 1/N / std * (N * dx_norm - \n",
        "                      dx_norm.sum(axis=0) - \n",
        "                      x_norm * (dx_norm * x_norm).sum(axis=0))    \n",
        "\n",
        "    return dx, dgamma, dbeta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi7CsvAc066r"
      },
      "source": [
        ""
      ]
    }
  ]
}