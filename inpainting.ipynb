{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHul3cVGWP9h"
      },
      "source": [
        "Code for **\"Inpainting\"** figures $6$, $8$ and 7 (top) from the main paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PazVbuf7WP9l",
        "outputId": "aa7f69b9-38bf-4258-9783-2601f973a029"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n*Uncomment if running on colab* \\nSet Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "*Uncomment if running on colab*\n",
        "Set Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab\n",
        "\"\"\"\n",
        "# !git clone https://github.com/DmitryUlyanov/deep-image-prior\n",
        "# !mv deep-image-prior/* ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHa2DLZ0WP9m"
      },
      "source": [
        "# Import libs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DmitryUlyanov/deep-image-prior\n",
        "!mv deep-image-prior/* ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT7ZldHAWlkK",
        "outputId": "b4ec2c54-206c-4432-dc87-a6b72bf126f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'deep-image-prior' already exists and is not an empty directory.\n",
            "mv: cannot stat 'deep-image-prior/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "TXTDVdSXWP9n",
        "outputId": "1fe621ea-f718-4599-899a-fdecc4f5767a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Detected that PyTorch and torchvision were compiled with different CUDA major versions. PyTorch has CUDA Version=11.8 and torchvision has CUDA Version=12.4. Please reinstall the torchvision that matches your PyTorch install.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5ce44483b9b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minpainting_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils/inpainting_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageDraw\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFont\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_text_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils/common_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Don't re-order these, we need to load the _C extension (done when importing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0m_check_cuda_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/extension.py\u001b[0m in \u001b[0;36m_check_cuda_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mt_minor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_version\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt_major\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtv_major\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;34m\"Detected that PyTorch and torchvision were compiled with different CUDA major versions. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;34mf\"PyTorch has CUDA Version={t_major}.{t_minor} and torchvision has \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Detected that PyTorch and torchvision were compiled with different CUDA major versions. PyTorch has CUDA Version=11.8 and torchvision has CUDA Version=12.4. Please reinstall the torchvision that matches your PyTorch install."
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "import numpy as np\n",
        "from models.resnet import ResNet\n",
        "from models.unet import UNet\n",
        "from models.skip import skip\n",
        "import torch\n",
        "import torch.optim\n",
        "\n",
        "from utils.inpainting_utils import *\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "PLOT = True\n",
        "imsize = -1\n",
        "dim_div_by = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPS-z_WrWP9n"
      },
      "source": [
        "# Choose figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrF7xU0DWP9o"
      },
      "outputs": [],
      "source": [
        "## Fig 6\n",
        "# img_path  = 'data/inpainting/vase.png'\n",
        "# mask_path = 'data/inpainting/vase_mask.png'\n",
        "\n",
        "## Fig 8\n",
        "# img_path  = 'data/inpainting/library.png'\n",
        "# mask_path = 'data/inpainting/library_mask.png'\n",
        "\n",
        "## Fig 7 (top)\n",
        "img_path  = 'data/inpainting/kate.png'\n",
        "mask_path = 'data/inpainting/kate_mask.png'\n",
        "\n",
        "# Another text inpainting example\n",
        "# img_path  = 'data/inpainting/peppers.png'\n",
        "# mask_path = 'data/inpainting/peppers_mask.png'\n",
        "\n",
        "NET_TYPE = 'skip_depth6' # one of skip_depth4|skip_depth2|UNET|ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfT3_HrSWP9o"
      },
      "source": [
        "# Load mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JD-kj3EWP9o"
      },
      "outputs": [],
      "source": [
        "img_pil, img_np = get_image(img_path, imsize)\n",
        "img_mask_pil, img_mask_np = get_image(mask_path, imsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD5WEZo4WP9p"
      },
      "source": [
        "### Center crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPWCkW8HWP9p"
      },
      "outputs": [],
      "source": [
        "img_mask_pil = crop_image(img_mask_pil, dim_div_by)\n",
        "img_pil      = crop_image(img_pil,      dim_div_by)\n",
        "\n",
        "img_np      = pil_to_np(img_pil)\n",
        "img_mask_np = pil_to_np(img_mask_pil)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUaSzRfAWP9q"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "hQrT5iMxW3Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify CUDA is available\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available! Using GPU for calculations.\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Falling back to CPU.\")\n",
        "    #If CUDA is not available, change dtype to CPU tensor\n",
        "    dtype = torch.FloatTensor"
      ],
      "metadata": {
        "id": "M_y_sqZLXWez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bwj4wvFTWP9q"
      },
      "outputs": [],
      "source": [
        "img_mask_var = np_to_torch(img_mask_np).type(dtype)\n",
        "\n",
        "plot_image_grid([img_np, img_mask_np, img_mask_np*img_np], 3,11);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOrNeRToWP9q"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g77CduvbWP9q"
      },
      "outputs": [],
      "source": [
        "pad = 'reflection' # 'zero'\n",
        "OPT_OVER = 'net'\n",
        "OPTIMIZER = 'adam'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo_rgkOMWP9q"
      },
      "outputs": [],
      "source": [
        "if 'vase.png' in img_path:\n",
        "    INPUT = 'meshgrid'\n",
        "    input_depth = 2\n",
        "    LR = 0.01\n",
        "    num_iter = 5001\n",
        "    param_noise = False\n",
        "    show_every = 50\n",
        "    figsize = 5\n",
        "    reg_noise_std = 0.03\n",
        "\n",
        "    net = skip(input_depth, img_np.shape[0],\n",
        "               num_channels_down = [128] * 5,\n",
        "               num_channels_up   = [128] * 5,\n",
        "               num_channels_skip = [0] * 5,\n",
        "               upsample_mode='nearest', filter_skip_size=1, filter_size_up=3, filter_size_down=3,\n",
        "               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
        "\n",
        "elif ('kate.png' in img_path) or ('peppers.png' in img_path):\n",
        "    # Same params and net as in super-resolution and denoising\n",
        "    INPUT = 'noise'\n",
        "    input_depth = 32\n",
        "    LR = 0.01\n",
        "    num_iter = 6001\n",
        "    param_noise = False\n",
        "    show_every = 50\n",
        "    figsize = 5\n",
        "    reg_noise_std = 0.03\n",
        "\n",
        "    net = skip(input_depth, img_np.shape[0],\n",
        "               num_channels_down = [128] * 5,\n",
        "               num_channels_up =   [128] * 5,\n",
        "               num_channels_skip =    [128] * 5,\n",
        "               filter_size_up = 3, filter_size_down = 3,\n",
        "               upsample_mode='nearest', filter_skip_size=1,\n",
        "               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
        "\n",
        "elif 'library.png' in img_path:\n",
        "\n",
        "    INPUT = 'noise'\n",
        "    input_depth = 1\n",
        "\n",
        "    num_iter = 3001\n",
        "    show_every = 50\n",
        "    figsize = 8\n",
        "    reg_noise_std = 0.00\n",
        "    param_noise = True\n",
        "\n",
        "    if 'skip' in NET_TYPE:\n",
        "\n",
        "        depth = int(NET_TYPE[-1])\n",
        "        net = skip(input_depth, img_np.shape[0],\n",
        "               num_channels_down = [16, 32, 64, 128, 128, 128][:depth],\n",
        "               num_channels_up =   [16, 32, 64, 128, 128, 128][:depth],\n",
        "               num_channels_skip =    [0, 0, 0, 0, 0, 0][:depth],\n",
        "               filter_size_up = 3,filter_size_down = 5,  filter_skip_size=1,\n",
        "               upsample_mode='nearest', # downsample_mode='avg',\n",
        "               need1x1_up=False,\n",
        "               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
        "\n",
        "        LR = 0.01\n",
        "\n",
        "    elif NET_TYPE == 'UNET':\n",
        "\n",
        "        net = UNet(num_input_channels=input_depth, num_output_channels=3,\n",
        "                   feature_scale=8, more_layers=1,\n",
        "                   concat_x=False, upsample_mode='deconv',\n",
        "                   pad='zero', norm_layer=torch.nn.InstanceNorm2d, need_sigmoid=True, need_bias=True)\n",
        "\n",
        "        LR = 0.001\n",
        "        param_noise = False\n",
        "\n",
        "    elif NET_TYPE == 'ResNet':\n",
        "\n",
        "        net = ResNet(input_depth, img_np.shape[0], 8, 32, need_sigmoid=True, act_fun='LeakyReLU')\n",
        "\n",
        "        LR = 0.001\n",
        "        param_noise = False\n",
        "\n",
        "    else:\n",
        "        assert False\n",
        "else:\n",
        "    assert False\n",
        "\n",
        "net = net.type(dtype)\n",
        "net_input = get_noise(input_depth, INPUT, img_np.shape[1:]).type(dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBUgVTt6WP9r"
      },
      "outputs": [],
      "source": [
        "# Compute number of parameters\n",
        "s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
        "print ('Number of params: %d' % s)\n",
        "\n",
        "# Loss\n",
        "mse = torch.nn.MSELoss().type(dtype)\n",
        "\n",
        "img_var = np_to_torch(img_np).type(dtype)\n",
        "mask_var = np_to_torch(img_mask_np).type(dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aVQ0QlVWP9r"
      },
      "source": [
        "# Main loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "dgEr-ZyeWP9r"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "def closure():\n",
        "\n",
        "    global i\n",
        "\n",
        "    if param_noise:\n",
        "        for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
        "            n = n + n.detach().clone().normal_() * n.std() / 50\n",
        "\n",
        "    net_input = net_input_saved\n",
        "    if reg_noise_std > 0:\n",
        "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "\n",
        "\n",
        "    out = net(net_input)\n",
        "\n",
        "    total_loss = mse(out * mask_var, img_var * mask_var)\n",
        "    total_loss.backward()\n",
        "\n",
        "    print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\\r', end='')\n",
        "    if  PLOT and i % show_every == 0:\n",
        "        out_np = torch_to_np(out)\n",
        "        plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "net_input_saved = net_input.detach().clone()\n",
        "noise = net_input.detach().clone()\n",
        "\n",
        "p = get_params(OPT_OVER, net, net_input)\n",
        "optimize(OPTIMIZER, p, closure, LR, num_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5Oi0oedWP9r"
      },
      "outputs": [],
      "source": [
        "out_np = torch_to_np(net(net_input))\n",
        "plot_image_grid([out_np], factor=5);"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}